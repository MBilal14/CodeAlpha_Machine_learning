{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f645cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "#   TASK 3: HANDWRITTEN CHARACTER RECOGNITION (CNN MODEL)\n",
    "#   Single File Project - MNIST / EMNIST Supported\n",
    "# ========================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# ========================================================\n",
    "# 1. LOAD DATASET (MNIST DIGITS)\n",
    "# For EMNIST: use script below (comment/uncomment)\n",
    "# ========================================================\n",
    "\n",
    "print(\"Loading MNIST dataset...\")\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape → CNN expects 4D input\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test  = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train / 255.0\n",
    "X_test  = X_test / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"Dataset Loaded Successfully!\")\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# 2. DATA AUGMENTATION\n",
    "# ========================================================\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# 3. BUILD CNN MODEL\n",
    "# ========================================================\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(10, activation='softmax')  # 10 classes for MNIST digits\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# 4. TRAIN MODEL\n",
    "# ========================================================\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=64),\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# 5. EVALUATION\n",
    "# ========================================================\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# 6. SAVE MODEL\n",
    "# ========================================================\n",
    "\n",
    "model.save(\"handwritten_character_model.h5\")\n",
    "print(\"Model Saved → handwritten_character_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Loading EMNIST Letters dataset...\")\n",
    "ds_train, ds_test = tfds.load('emnist/letters', split=['train', 'test'], as_supervised=True)\n",
    "\n",
    "# Convert to arrays\n",
    "X_train = np.array([img.numpy() for img, label in ds_train])\n",
    "y_train = np.array([label.numpy() for img, label in ds_train])\n",
    "\n",
    "X_test = np.array([img.numpy() for img, label in ds_test])\n",
    "y_test = np.array([label.numpy() for img, label in ds_test])\n",
    "\n",
    "# Reshape + Normalize\n",
    "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# Labels start from 1–26 → shift to 0–25\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "y_train = to_categorical(y_train, 26)\n",
    "y_test  = to_categorical(y_test, 26)\n",
    "\n",
    "print(\"EMNIST Loaded.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
