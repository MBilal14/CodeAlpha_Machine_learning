{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c85d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Disease Prediction - CodeAlpha Internship (Task 4)\n",
    "Single-file project:\n",
    "- Loads a structured medical dataset (CSV)\n",
    "- Preprocesses, feature-engineers\n",
    "- Trains: Logistic Regression, SVM, RandomForest, XGBoost\n",
    "- Evaluates: Accuracy, Precision, Recall, F1, ROC-AUC\n",
    "- Saves best model artifact (pickle)\n",
    "- Usage:\n",
    "    python disease_prediction.py --data path/to/diabetes.csv --target Outcome --out_dir ./artifacts\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_available = True\n",
    "except Exception:\n",
    "    xgb_available = False\n",
    "    # If xgboost not installed, user can pip install xgboost\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "def basic_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Example transformations:\n",
    "    - Create BMI category if 'BMI' exists\n",
    "    - Create 'age_group' buckets if 'Age' exists\n",
    "    - Create debt-to-income style ratio if income/expense columns exist\n",
    "    These are simple examples; adapt for your chosen dataset.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if 'BMI' in df.columns:\n",
    "        df['bmi_high'] = (df['BMI'] > 30).astype(int)\n",
    "    if 'Age' in df.columns:\n",
    "        df['age_over_50'] = (df['Age'] > 50).astype(int)\n",
    "    # Example: if glucose and insulin present, create ratio\n",
    "    if 'Glucose' in df.columns and 'Insulin' in df.columns:\n",
    "        df['glucose_insulin_ratio'] = df['Glucose'] / (df['Insulin'] + 1e-6)\n",
    "    return df\n",
    "\n",
    "def prepare_features(df, target_col):\n",
    "    # Drop rows where target is missing\n",
    "    df = df.dropna(subset=[target_col])\n",
    "\n",
    "    # Separate X/y\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col].astype(int)\n",
    "\n",
    "    # Identify numeric and categorical\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "\n",
    "    # Simple imputation / encode\n",
    "    if len(categorical_cols) > 0:\n",
    "        X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Impute numeric with median\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X[numeric_cols] = imputer.fit_transform(X[numeric_cols])\n",
    "\n",
    "    return X, y, numeric_cols\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, out_dir, random_state=42):\n",
    "    results = {}\n",
    "    models = {}\n",
    "\n",
    "    # Common scaler pipeline for linear models\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr_pipe = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('clf', LogisticRegression(max_iter=2000, random_state=random_state))\n",
    "    ])\n",
    "    lr_pipe.fit(X_train, y_train)\n",
    "    models['LogisticRegression'] = lr_pipe\n",
    "\n",
    "    # SVM (probability=True for ROC AUC)\n",
    "    svm_pipe = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('clf', SVC(kernel='rbf', probability=True, random_state=random_state))\n",
    "    ])\n",
    "    svm_pipe.fit(X_train, y_train)\n",
    "    models['SVM'] = svm_pipe\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=random_state, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    models['RandomForest'] = rf\n",
    "\n",
    "    # XGBoost (if available)\n",
    "    if xgb_available:\n",
    "        xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_state)\n",
    "        xgb.fit(X_train, y_train)\n",
    "        models['XGBoost'] = xgb\n",
    "\n",
    "    # Evaluate each\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        # probabilities for ROC-AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(X_test)[:,1]\n",
    "        else:\n",
    "            # SVM has predict_proba after probability=True; fallback:\n",
    "            try:\n",
    "                y_proba = model.decision_function(X_test)\n",
    "                # scale to [0,1]\n",
    "                y_proba = (y_proba - y_proba.min()) / (y_proba.max() - y_proba.min() + 1e-9)\n",
    "            except Exception:\n",
    "                y_proba = y_pred\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "            \"precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "            \"recall\": float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "            \"f1\": float(f1_score(y_test, y_pred, zero_division=0)),\n",
    "            \"roc_auc\": float(roc_auc_score(y_test, y_proba)),\n",
    "            \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
    "        }\n",
    "        results[name] = metrics\n",
    "\n",
    "    # Choose best by roc_auc\n",
    "    best_name = max(results.keys(), key=lambda k: results[k]['roc_auc'])\n",
    "    best_model = models[best_name]\n",
    "    print(f\"Best model: {best_name} (ROC-AUC = {results[best_name]['roc_auc']:.4f})\")\n",
    "\n",
    "    # Save artifact\n",
    "    artifact = {\n",
    "        \"model\": best_model,\n",
    "        \"results\": results,\n",
    "        \"feature_columns\": X_train.columns.tolist()\n",
    "    }\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    artifact_path = os.path.join(out_dir, \"disease_model_artifact.pkl\")\n",
    "    with open(artifact_path, \"wb\") as f:\n",
    "        pickle.dump(artifact, f)\n",
    "\n",
    "    # Save results summary\n",
    "    summary_path = os.path.join(out_dir, \"results_summary.json\")\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(\"Saved artifact to:\", artifact_path)\n",
    "    print(\"Saved results summary to:\", summary_path)\n",
    "    return results, artifact_path\n",
    "\n",
    "def main(args):\n",
    "    # Load\n",
    "    print(\"Loading dataset:\", args.data)\n",
    "    df = load_data(args.data)\n",
    "\n",
    "    # Basic feature engineering\n",
    "    df_fe = basic_feature_engineering(df)\n",
    "\n",
    "    # Prepare features\n",
    "    X, y, numeric_cols = prepare_features(df_fe, args.target)\n",
    "    print(\"Feature matrix shape:\", X.shape)\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=args.test_size, stratify=y, random_state=args.random_state\n",
    "    )\n",
    "\n",
    "    # Train & evaluate\n",
    "    results, artifact_path = train_and_evaluate(X_train, X_test, y_train, y_test, args.out_dir, args.random_state)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nModel evaluation summary:\")\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"\\n--- {model_name} ---\")\n",
    "        for k, v in metrics.items():\n",
    "            if k != 'confusion_matrix':\n",
    "                print(f\"{k}: {v:.4f}\")\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Disease Prediction (Task 4) - train and evaluate models\")\n",
    "    parser.add_argument(\"--data\", type=str, required=True, help=\"Path to CSV dataset (structured).\")\n",
    "    parser.add_argument(\"--target\", type=str, default=\"Outcome\", help=\"Name of target column (binary: 0/1).\")\n",
    "    parser.add_argument(\"--out_dir\", type=str, default=\"./artifacts\", help=\"Output directory for model and results.\")\n",
    "    parser.add_argument(\"--test_size\", type=float, default=0.2, help=\"Test split fraction.\")\n",
    "    parser.add_argument(\"--random_state\", type=int, default=42, help=\"Random seed.\")\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
